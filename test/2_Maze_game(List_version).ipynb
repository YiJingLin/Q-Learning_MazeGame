{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class agent:\n",
    "    def __init__(self, epsilon, gamma, alpha, \n",
    "                 state, actions, q_table):\n",
    "        self.epsilon = epsilon # epsilon-greedy policy, default = 0.9\n",
    "        self.gamma = gamma # decay-rate, default = 0.9\n",
    "        self.alpha = alpha # learning-rate, default = 0.1\n",
    "        \n",
    "        self.state = state # coordinate tuple, example, (2,3)\n",
    "        self.actions = actions # 1-D action list, ['up', 'down', 'left', 'right']\n",
    "        self.q_table = q_table # 3-D array, 3rd dimension for action reward\n",
    "    \n",
    "    def choose_action(self):\n",
    "        state_actions = self.q_table[self.state] # numpy \n",
    "        # get random rate and compare to epsilon\n",
    "        randomRate = np.random.uniform()\n",
    "        if randomRate > self.epsilon :\n",
    "            action = self.actions.index(np.random.choice(self.actions)) # choose randomly\n",
    "        elif state_actions.max() == 0 :\n",
    "            p=[]\n",
    "            count=0\n",
    "            for idx, reward in enumerate(state_actions) :\n",
    "                if reward == 0:\n",
    "                    p.append(1)\n",
    "                    count+=1\n",
    "                else:\n",
    "                    p.append(0)\n",
    "            \n",
    "            p = np.array(p)/count\n",
    "            action = self.actions.index(np.random.choice(self.actions, p=list(p)))\n",
    "        else:\n",
    "            action = state_actions.argmax() # derive action's index with highest reward\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def update_q_table(self, reward, action, nxt_state):\n",
    "        # Q predict : choose action's reward at current state on q_table\n",
    "        q_predict = self.q_table[self.state][action]\n",
    "        # Q target : consider next step reward\n",
    "        if nxt_state in ['win', 'fail'] :\n",
    "            q_target = reward\n",
    "        else:\n",
    "            q_target = reward + self.gamma * self.q_table[nxt_state][action]\n",
    "        # accumulate\n",
    "        self.q_table[self.state][action] += self.alpha * (q_target - q_predict) \n",
    "        self.state = nxt_state # update state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class maze_env:\n",
    "    def __init__(self, actions):\n",
    "        self.unit = 40\n",
    "        self.actions = actions\n",
    "        \n",
    "    def build_map(self, size, target, t_reward, fail_list, f_reward_list):\n",
    "        # check target\n",
    "        if not (target[0] < size[0] and target[1] < size[1]) :\n",
    "            print(\"target out of bound !\")\n",
    "            return\n",
    "        if not t_reward > 0:\n",
    "            print(\"target\\'s reward should be positive !\")\n",
    "        # check fail block\n",
    "        for idx, fail in enumerate(fail_list):\n",
    "            if not (fail[0] < size[0] and fail[1] < size[1]):\n",
    "                print('No '+str(idx)+'. fail block out of bound !')\n",
    "                return\n",
    "            if not f_reward_list[idx] < 0:\n",
    "                print('No '+str(idx)+'. fail\\'s reward should be negative !')\n",
    "                return \n",
    "            if fail == target :\n",
    "                print('No '+str(idx)+'. fail have same coordinate with target !')\n",
    "                return\n",
    "        self.size = size\n",
    "        self.target = target\n",
    "        self.fail_list = fail_list\n",
    "        \n",
    "        self.map = np.zeros((size))\n",
    "        self.map[target] = t_reward\n",
    "        for idx, fail in enumerate(fail_list):\n",
    "            self.map[fail] = f_reward_list[idx]\n",
    "        \n",
    "        print('game map : ')\n",
    "        print(self.map)\n",
    "        return\n",
    "    \n",
    "    def env_feedback(self, state, action):\n",
    "        # strategy : calculate coordinate first, and then check finish or not\n",
    "        nxt_state = self.cal_coordinate(state, action)\n",
    "        \n",
    "        reward = self.map[nxt_state]\n",
    "        if nxt_state in self.fail_list:\n",
    "            nxt_state = 'fail'\n",
    "        elif nxt_state == self.target:\n",
    "            nxt_state = 'win'\n",
    "            \n",
    "        return nxt_state, reward\n",
    "    \n",
    "    def cal_coordinate(self, state, action):\n",
    "        nxt_state = ()\n",
    "        move = ()\n",
    "        \n",
    "        if action == 0: # up\n",
    "            move = (-1,0)\n",
    "            if state[0] == 0: \n",
    "                nxt_state = state # hit the top wall\n",
    "            else: \n",
    "                nxt_state = tuple([sum(x) for x in zip(state,move)])\n",
    "                \n",
    "        elif action == 1: #down\n",
    "            move = (1,0)\n",
    "            if state[0] == self.size[0]-1 : \n",
    "                nxt_state = state # hit the bottom wall\n",
    "            else: \n",
    "                nxt_state = tuple([sum(x) for x in zip(state,move)])\n",
    "                \n",
    "        elif action == 2: #left\n",
    "            move = (0,-1)\n",
    "            if state[1] == 0: \n",
    "                nxt_state = state # hit the left wall\n",
    "            else: \n",
    "                nxt_state = tuple([sum(x) for x in zip(state,move)])\n",
    "                \n",
    "        elif action == 3: # right\n",
    "            move = (0,1)\n",
    "            if state[1] == self.size[1]-1 : \n",
    "                nxt_state = state # hit the right wall\n",
    "            else: \n",
    "                nxt_state = tuple([sum(x) for x in zip(state,move)])\n",
    "        \n",
    "        return nxt_state\n",
    "    \n",
    "    def create_q_table(self):\n",
    "        q_table = np.zeros(self.size + (len(self.actions),))\n",
    "        print('Q_table.shape :')\n",
    "        print(q_table.shape)\n",
    "        return np.array(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPISODES = 20\n",
    "ACTIONS = ['up', 'down', 'left', 'right']\n",
    "initSTATE = (0,0)\n",
    "SIZE = (3,4) # maze size\n",
    "\n",
    "EPSILON = 0.9\n",
    "GAMMA = 0.9\n",
    "ALPHA = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game map : \n",
      "[[ 0.  0.  0.  0.]\n",
      " [-7. -5. -3.  0.]\n",
      " [ 5.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "target = (2,0)\n",
    "t_reward = 5\n",
    "fail_list = [(1,0),(1,1),(1,2)]\n",
    "f_reward_list = np.random.randint(low=-7, high=-1, size=len(fail_list))\n",
    "\n",
    "Maze = maze_env(ACTIONS)\n",
    "Maze.build_map(SIZE, target, t_reward, fail_list, f_reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q_table.shape :\n",
      "(3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "Q_table = Maze.create_q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Agent = agent(epsilon= EPSILON, gamma= GAMMA, alpha= ALPHA,\n",
    "             state = initSTATE, actions= ACTIONS,q_table= Q_table.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1) > fail\n",
      " Episode. 0 finished ... ,total step : 2\n",
      "fail\n",
      " Episode. 1 finished ... ,total step : 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6f17670dc0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Episode. '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' finished ... ,total step : '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def path(state, is_terminated):\n",
    "    print(state, end='')\n",
    "    if not is_terminated: print(' > ', end='')\n",
    "\n",
    "# main process RL - Q_Learning\n",
    "for episode in range(EPISODES):\n",
    "    Agent.state = initSTATE\n",
    "    is_terminated = False\n",
    "    count = 0\n",
    "    while not is_terminated :\n",
    "        # choose action and get env. feedback\n",
    "        action = Agent.choose_action()\n",
    "#         print('action:'+str(action), end='')\n",
    "        nxt_state, reward = Maze.env_feedback(state=Agent.state, action=action)\n",
    "#         print('nxt_state:'+str(nxt_state), end='')\n",
    "        # update Q_table\n",
    "        Agent.update_q_table(reward=reward, action=action, nxt_state=nxt_state)\n",
    "        \n",
    "        if nxt_state in ['win','fail']:\n",
    "            is_terminated = True\n",
    "        # update visual info\n",
    "        path(Agent.state, is_terminated)\n",
    "        Agent.state = nxt_state\n",
    "        count +=1\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    print('\\n Episode. '+str(episode)+' finished ... ,total step : '+str(count))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.  , -0.38,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ]],\n",
       "\n",
       "       [[ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ]],\n",
       "\n",
       "       [[ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ],\n",
       "        [ 0.  ,  0.  ,  0.  ,  0.  ]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(Agent.q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Give punishment when bumping the wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail\n",
      " Episode. 0 finished ... ,total step : 1\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 1 finished ... ,total step : 42\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > fail\n",
      " Episode. 2 finished ... ,total step : 36\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 3 finished ... ,total step : 33\n",
      "(0, 1) > fail\n",
      " Episode. 4 finished ... ,total step : 2\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 5 finished ... ,total step : 19\n",
      "(0, 1) > (0, 0) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 2) > (2, 1) > (2, 1) > win\n",
      " Episode. 6 finished ... ,total step : 33\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 7 finished ... ,total step : 71\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 8 finished ... ,total step : 9\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 9 finished ... ,total step : 81\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > fail\n",
      " Episode. 10 finished ... ,total step : 23\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 11 finished ... ,total step : 51\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 12 finished ... ,total step : 16\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 13 finished ... ,total step : 47\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 14 finished ... ,total step : 38\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 15 finished ... ,total step : 20\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 16 finished ... ,total step : 20\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > fail\n",
      " Episode. 17 finished ... ,total step : 7\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > fail\n",
      " Episode. 18 finished ... ,total step : 20\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 3) > (0, 3) > (1, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 19 finished ... ,total step : 43\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 20 finished ... ,total step : 26\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 21 finished ... ,total step : 76\n",
      "(0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 22 finished ... ,total step : 40\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 23 finished ... ,total step : 5\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > fail\n",
      " Episode. 24 finished ... ,total step : 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 25 finished ... ,total step : 32\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 26 finished ... ,total step : 46\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 3) > (1, 3) > (2, 3) > (2, 2) > (2, 1) > win\n",
      " Episode. 27 finished ... ,total step : 10\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > fail\n",
      " Episode. 28 finished ... ,total step : 34\n",
      "(0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 0) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > (0, 1) > (0, 2) > fail\n",
      " Episode. 29 finished ... ,total step : 92\n"
     ]
    }
   ],
   "source": [
    "EPISODES = 30\n",
    "\n",
    "def path(state, is_terminated):\n",
    "    print(state, end='')\n",
    "    if not is_terminated: print(' > ', end='')\n",
    "\n",
    "# main process RL - Q_Learning\n",
    "for episode in range(EPISODES):\n",
    "    Agent.state = initSTATE\n",
    "    is_terminated = False\n",
    "    count = 0\n",
    "    while not is_terminated :\n",
    "        # choose action and get env. feedback\n",
    "        action = Agent.choose_action()\n",
    "#         print('action:'+str(action), end='')\n",
    "        nxt_state, reward = Maze.env_feedback(state=Agent.state, action=action)\n",
    "#         print('nxt_state:'+str(nxt_state), end='')\n",
    "        # update Q_table\n",
    "        ###########################################\n",
    "        if Agent.state == nxt_state: # bump the wall\n",
    "            reward = -1\n",
    "        ###########################################\n",
    "        Agent.update_q_table(reward=reward, action=action, nxt_state=nxt_state)\n",
    "        \n",
    "        if nxt_state in ['win','fail']:\n",
    "            is_terminated = True\n",
    "        # update visual info\n",
    "        path(Agent.state, is_terminated)\n",
    "        Agent.state = nxt_state\n",
    "        count +=1\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    print('\\n Episode. '+str(episode)+' finished ... ,total step : '+str(count))\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -3.94039900e-01,  -5.42000000e-01,  -2.97010000e-01,\n",
       "          -8.43655117e-02],\n",
       "        [ -1.31254187e+00,  -1.30264312e+00,  -1.30598112e-01,\n",
       "          -1.22839129e-01],\n",
       "        [ -4.90099501e-01,  -2.27813116e+00,  -1.17529228e-01,\n",
       "          -1.45932627e-01],\n",
       "        [ -1.00000000e-01,  -2.24372972e-02,  -3.03500959e-02,\n",
       "          -2.97010000e-01]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "        [ -5.12579511e-02,  -4.69532790e-02,  -7.60000000e-01,\n",
       "          -1.00000000e-01]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           0.00000000e+00],\n",
       "        [ -2.00000000e-01,  -1.00000000e-01,   1.35500000e+00,\n",
       "          -8.10000000e-04],\n",
       "        [ -7.60000000e-01,  -1.00000000e-01,   1.26000000e-01,\n",
       "          -1.71000000e-02],\n",
       "        [ -2.19510000e-03,  -1.00000000e-01,   4.05000000e-03,\n",
       "          -1.00000000e-01]]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Agent.q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
