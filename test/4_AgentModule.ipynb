{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Env:\n",
    "    def __init__(self, map_size=(5,5), target=(3,3), target_reward=10,\n",
    "                 fail_list=[(3,2),(2,3)], fail_punishment_list=[-5, -5],\n",
    "                 wall_punishment = -1):\n",
    "        self._MAP_SIZE = map_size\n",
    "        self._WALL_PUNISHMENT = wall_punishment\n",
    "        \n",
    "        self.TARGET = target\n",
    "        self.FAIL_LIST = fail_list\n",
    "        self.REWARD_MAP = self._assign_reward_to_map(target, target_reward,\n",
    "                                               fail_list, fail_punishment_list)\n",
    "        \n",
    "    def _assign_reward_to_map(self, target, target_reward, fail_list, fail_punishment_list):\n",
    "        tmp_map = np.zeros(self._MAP_SIZE, dtype='int')\n",
    "        target = self.TARGET\n",
    "        fail_list = self.FAIL_LIST\n",
    "        \n",
    "        # assign reward when reach the target \n",
    "        tmp_map[target] = target_reward\n",
    "        \n",
    "        # assign failure punishment\n",
    "        for coordinate, punishment in zip(fail_list, fail_punishment_list):\n",
    "            tmp_map[coordinate] = punishment\n",
    "        \n",
    "        return tmp_map\n",
    "    \n",
    "    def take_action(self, state, action):\n",
    "        reward = 0\n",
    "        next_state = state\n",
    "        terminal = False\n",
    "        \n",
    "        if action=='up':\n",
    "            if state[0]==0:\n",
    "                next_state = state # stay in place\n",
    "                reward = self._WALL_PUNISHMENT\n",
    "            else:\n",
    "                next_state = (state[0]-1, state[1])\n",
    "                reward = self.REWARD_MAP[state]\n",
    "        elif action=='down':\n",
    "            if state[0]==self._MAP_SIZE[0]-1:\n",
    "                next_state = state # stay in place\n",
    "                reward = self._WALL_PUNISHMENT\n",
    "            else:\n",
    "                next_state = (state[0]+1, state[1])\n",
    "                reward = self.REWARD_MAP[state]\n",
    "        elif action=='left':\n",
    "            if state[1]==0:\n",
    "                next_state = state # stay in place\n",
    "                reward = self._WALL_PUNISHMENT\n",
    "            else:\n",
    "                next_state = (state[0], state[1]-1)\n",
    "                reward = self.REWARD_MAP[state]\n",
    "        elif action=='right':\n",
    "            if state[1]==self._MAP_SIZE[1]-1:\n",
    "                next_state = state # stay in place\n",
    "                reward = self._WALL_PUNISHMENT\n",
    "            else:\n",
    "                next_state = (state[0], state[1]+1)\n",
    "                reward = self.REWARD_MAP[state]\n",
    "        \n",
    "        # check if terminal\n",
    "        if self.REWARD_MAP[next_state]!=0:\n",
    "            terminal=True\n",
    "            \n",
    "        return next_state, reward, terminal\n",
    "    \n",
    "    \n",
    "    def showEnvInfo(self, next_state, reward, terminal):\n",
    "        print(\"-->{}\".format(next_state),end='')\n",
    "        if terminal:\n",
    "            if self.REWARD_MAP[next_state]>0:\n",
    "                print(\"  >>>win<<<\")\n",
    "            elif self.REWARD_MAP[next_state]<0:\n",
    "                print(\"  >>>fail<<<\")\n",
    "            else:\n",
    "                print(\"(*&)(*({)(something wrong~\")\n",
    "    \n",
    "    def render(self):\n",
    "        time.sleep(0.1)\n",
    "        self.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Agent:\n",
    "    \n",
    "    # Agent will hold a map (which represent record table)\n",
    "    def __init__(self, table_size=(5,5), epsilon=0.9, alpha=0.1, gamma=0.8, action_list=['up','down','left','right']):\n",
    "        self._TABLE_SIZE = table_size\n",
    "        self._EPSILON = epsilon\n",
    "        self._ALPHA = alpha # learning rate\n",
    "        self._GAMMA = gamma\n",
    "        \n",
    "        self.ACTION_SIZE = len(action_list)\n",
    "        self.ACTION_LIST = action_list\n",
    "        \n",
    "        self.table = np.zeros(table_size + (len(action_list),), dtype='float16')  \n",
    "    \n",
    "    def new_episode(self):\n",
    "        self.state = (0,0)\n",
    "        return self.state\n",
    "    \n",
    "    def learn(self):\n",
    "        pass\n",
    "    \n",
    "class QLearningAgent(Agent):\n",
    "    def __init__(self, table_size=(5,5), epsilon=0.9, alpha=0.1, gamma=0.8, action_list=['up','down','left','right']):\n",
    "        super().__init__(table_size=table_size, epsilon=epsilon, alpha=alpha, gamma=gamma, action_list=action_list)\n",
    "    \n",
    "    def learn(self, reward, action, next_state):\n",
    "        action_idx = self.ACTION_LIST.index(action)        \n",
    "        origin = self.table[self.state+(action_idx,)]\n",
    "        #### choose max reward from next_state\n",
    "        prediction = self._GAMMA * self.table[next_state].max()\n",
    "        \n",
    "        self.table[self.state+(action_idx,)] = origin + self._ALPHA*(reward+prediction-origin)\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        # epsilon-greedy\n",
    "        rate = np.random.rand()\n",
    "        if rate > self._EPSILON or (self.table[state].max()==0 and self.table[state].min()==0):\n",
    "            # choose randomly\n",
    "            action = np.random.choice(self.ACTION_LIST)\n",
    "        elif self.table[state].max()==0 and self.table[state].min!=0:\n",
    "            # choose randomly from non-negative reward action\n",
    "            p_list = np.array([0] * self.ACTION_SIZE)\n",
    "            count= 0\n",
    "            for idx, reward in enumerate(self.table[state]):\n",
    "                if reward==0:\n",
    "                    p_list[idx]=1\n",
    "                    count+=1\n",
    "            p_list = list(p_list/count)\n",
    "            actionIdx = np.random.choice(self.ACTION_SIZE, 1, p_list)[0]\n",
    "            action = self.ACTION_LIST[actionIdx]\n",
    "        else:\n",
    "            # choose the action which contain max reward\n",
    "            actionIdx_with_highestReward = self.table[state].argmax()\n",
    "            action = self.ACTION_LIST[actionIdx_with_highestReward]\n",
    "        \n",
    "        return action\n",
    "    \n",
    "class SarsaAgent(Agent):\n",
    "    def __init__(self, table_size=(5,5), epsilon=0.9, alpha=0.1, gamma=0.8, action_list=['up','down','left','right']):\n",
    "        super().__init__(table_size=table_size, epsilon=epsilon, alpha=alpha, gamma=gamma, action_list=action_list)\n",
    "    \n",
    "    def learn(self, reward, action, next_action, next_state):\n",
    "        action_idx = self.ACTION_LIST.index(action)\n",
    "        next_action_idx = self.ACTION_LIST.index(next_action)\n",
    "        \n",
    "        origin = self.table[self.state+(action_idx,)]\n",
    "        ### choose exact reward according to next state and action\n",
    "        prediction = self._GAMMA * self.table[next_state+(next_action_idx,)]\n",
    "        \n",
    "        self.table[self.state+(action_idx,)] = origin + self._ALPHA*(reward+prediction-origin)\n",
    "    \n",
    "    def choose_action(self, state):\n",
    "        # epsilon-greedy\n",
    "        rate = np.random.rand()\n",
    "        if rate > self._EPSILON or (self.table[state].max()==0 and self.table[state].min()==0):\n",
    "            # choose randomly\n",
    "            action = np.random.choice(self.ACTION_LIST)\n",
    "        \n",
    "        else:\n",
    "            actionIdx_with_highestReward = self.table[state].argmax()\n",
    "            action = self.ACTION_LIST[actionIdx_with_highestReward]\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 2)-->(0, 1)-->(0, 2)-->(0, 3)-->(1, 3)-->(1, 2)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 1)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 2)-->(0, 3)-->(0, 4)-->(0, 4)-->(0, 4)-->(0, 4)-->(0, 3)-->(0, 4)-->(1, 4)-->(1, 4)-->(2, 4)-->(1, 4)-->(1, 3)-->(1, 4)-->(0, 4)-->(1, 4)-->(1, 3)-->(1, 2)-->(0, 2)-->(1, 2)-->(0, 2)-->(0, 3)-->(0, 3)-->(0, 4)-->(0, 3)-->(0, 2)-->(0, 3)-->(0, 2)-->(1, 2)-->(0, 2)-->(1, 2)-->(2, 2)-->(3, 2)-->(2, 2)-->(2, 1)-->(2, 0)-->(1, 0)-->(1, 0)-->(2, 0)-->(2, 0)-->(2, 1)-->(2, 0)-->(3, 0)-->(3, 0)-->(4, 0)-->(4, 0)-->(4, 0)-->(3, 0)-->(3, 0)-->(2, 0)-->(3, 0)-->(2, 0)-->(1, 0)-->(0, 0)-->(1, 0)-->(2, 0)-->(3, 0)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(1, 0)-->(1, 1)-->(1, 2)-->(2, 2)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 2)-->(0, 1)-->(0, 1)-->(1, 1)-->(1, 2)-->(2, 2)-->(1, 2)-->(0, 2)-->(0, 2)-->(0, 2)-->(0, 2)-->(0, 1)-->(0, 2)-->(0, 3)-->(0, 3)-->(1, 3)-->(1, 2)-->(1, 1)-->(1, 2)-->(1, 3)-->(1, 2)-->(2, 2)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(1, 1)-->(1, 0)-->(1, 0)-->(2, 0)-->(1, 0)-->(0, 0)-->(0, 1)-->(1, 1)-->(1, 2)-->(2, 2)-->(2, 1)-->(2, 0)-->(3, 0)-->(2, 0)-->(3, 0)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(2, 0)-->(3, 0)-->(3, 0)-->(4, 0)-->(4, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(1, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 1)-->(0, 1)-->(0, 2)-->(0, 3)-->(0, 3)-->(0, 2)-->(1, 2)-->(1, 3)-->(0, 3)-->(0, 4)-->(0, 4)-->(0, 3)-->(0, 3)-->(0, 2)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(2, 2)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(2, 0)-->(1, 0)-->(2, 0)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 1)-->(0, 1)-->(1, 1)-->(2, 1)-->(2, 2)-->(1, 2)-->(0, 2)-->(1, 2)-->(1, 1)-->(1, 2)-->(1, 1)-->(1, 2)-->(1, 3)-->(1, 4)-->(2, 4)-->(2, 4)-->(3, 4)-->(2, 4)-->(3, 4)-->(3, 4)-->(4, 4)-->(4, 3)-->(4, 2)-->(4, 3)-->(4, 4)-->(4, 3)-->(3, 3)  >>>win<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 2)-->(1, 2)-->(0, 2)-->(0, 3)-->(0, 4)-->(1, 4)-->(1, 4)-->(1, 4)-->(2, 4)-->(1, 4)-->(1, 3)-->(1, 2)-->(1, 3)-->(0, 3)-->(0, 3)-->(0, 4)-->(1, 4)-->(1, 3)-->(0, 3)-->(0, 4)-->(0, 3)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(1, 1)-->(2, 1)-->(2, 0)-->(2, 0)-->(2, 1)-->(2, 0)-->(1, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 0)-->(1, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(2, 0)-->(1, 0)-->(2, 0)-->(3, 0)-->(4, 0)-->(4, 0)-->(4, 1)-->(4, 2)-->(3, 2)-->(2, 2)-->(1, 2)-->(0, 2)-->(1, 2)-->(1, 1)-->(1, 2)-->(0, 2)-->(1, 2)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 1)-->(1, 0)-->(2, 0)-->(2, 1)-->(1, 1)-->(2, 1)-->(2, 0)-->(3, 0)-->(2, 0)-->(3, 0)-->(3, 0)-->(2, 0)-->(2, 1)-->(2, 0)-->(2, 0)-->(3, 0)-->(2, 0)-->(3, 0)-->(3, 0)-->(3, 0)-->(2, 0)-->(3, 0)-->(4, 0)-->(4, 0)-->(4, 1)-->(4, 0)-->(4, 1)-->(4, 0)-->(4, 1)-->(4, 2)-->(3, 2)-->(2, 2)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(2, 0)-->(2, 0)-->(1, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 2)-->(0, 2)-->(0, 1)-->(0, 2)-->(0, 1)-->(1, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 2)-->(0, 1)-->(0, 0)-->(0, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 1)-->(0, 2)-->(0, 1)-->(0, 1)-->(0, 1)-->(1, 1)-->(1, 2)-->(2, 2)-->(3, 2)-->(3, 3)  >>>win<<<\n",
      "(0, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(1, 1)-->(1, 2)-->(2, 2)-->(3, 2)-->(3, 3)  >>>win<<<\n",
      "(0, 0)-->(1, 0)-->(0, 0)-->(1, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 2)-->(0, 2)-->(0, 1)-->(1, 1)-->(2, 1)-->(2, 2)-->(1, 2)-->(0, 2)-->(0, 3)-->(1, 3)-->(0, 3)-->(0, 4)-->(0, 3)-->(0, 2)-->(0, 3)-->(0, 4)-->(0, 4)-->(0, 3)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 2)-->(0, 2)-->(0, 2)-->(1, 2)-->(2, 2)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(0, 2)-->(1, 2)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(0, 0)-->(1, 0)-->(1, 0)-->(1, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(2, 0)-->(3, 0)-->(4, 0)-->(4, 1)-->(4, 0)-->(4, 1)-->(4, 0)-->(3, 0)-->(3, 0)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 2)-->(0, 2)-->(1, 2)-->(1, 3)-->(1, 4)-->(1, 4)-->(2, 4)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 1)-->(1, 1)-->(1, 2)-->(0, 2)-->(0, 1)-->(1, 1)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 0)-->(0, 1)-->(0, 2)-->(0, 2)-->(0, 3)-->(0, 2)-->(1, 2)-->(0, 2)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 1)-->(1, 1)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(1, 1)-->(1, 0)-->(2, 0)-->(2, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(1, 1)-->(1, 2)-->(1, 3)-->(0, 3)-->(0, 4)-->(0, 4)-->(1, 4)-->(0, 4)-->(1, 4)-->(1, 3)-->(0, 3)-->(0, 4)-->(1, 4)-->(1, 4)-->(2, 4)-->(2, 4)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(1, 1)-->(1, 0)-->(1, 1)-->(1, 2)-->(1, 1)-->(0, 1)-->(0, 2)-->(0, 2)-->(0, 3)-->(0, 3)-->(0, 3)-->(0, 4)-->(0, 3)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 0)-->(1, 0)-->(1, 0)-->(1, 1)-->(1, 2)-->(1, 3)-->(1, 2)-->(0, 2)-->(1, 2)-->(1, 1)-->(0, 1)-->(1, 1)-->(1, 2)-->(1, 3)-->(1, 4)-->(0, 4)-->(0, 4)-->(0, 3)-->(0, 3)-->(0, 4)-->(0, 4)-->(1, 4)-->(1, 4)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(1, 1)-->(2, 1)-->(2, 0)-->(2, 1)-->(2, 0)-->(2, 1)-->(1, 1)-->(0, 1)-->(1, 1)-->(0, 1)-->(1, 1)-->(1, 2)-->(1, 3)-->(0, 3)-->(1, 3)-->(0, 3)-->(1, 3)-->(0, 3)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 1)-->(0, 0)-->(0, 0)-->(1, 0)-->(2, 0)-->(3, 0)-->(4, 0)-->(4, 0)-->(4, 1)-->(4, 2)-->(4, 1)-->(4, 0)-->(4, 1)-->(4, 0)-->(4, 1)-->(4, 0)-->(3, 0)-->(3, 0)-->(3, 0)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(1, 0)-->(1, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(1, 0)-->(1, 1)-->(1, 2)-->(2, 2)-->(3, 2)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 1)-->(0, 1)-->(0, 1)-->(0, 2)-->(0, 1)-->(1, 1)-->(2, 1)-->(3, 1)  >>>fail<<<\n",
      "(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(2, 0)-->(2, 0)-->(1, 0)-->(0, 0)-->(1, 0)-->(0, 0)-->(0, 1)-->(0, 1)-->(0, 1)-->(1, 1)-->(1, 0)-->(1, 1)-->(1, 0)-->(0, 0)-->(0, 0)-->(0, 1)-->(0, 2)-->(0, 3)-->(0, 4)-->(0, 4)-->(0, 3)-->(0, 4)-->(1, 4)-->(0, 4)-->(1, 4)-->(0, 4)-->(1, 4)-->(0, 4)-->(0, 4)-->(0, 3)-->(0, 2)-->(0, 2)-->(1, 2)-->(1, 1)-->(1, 2)-->(1, 1)-->(0, 1)-->(0, 0)-->(0, 0)-->(0, 0)-->(1, 0)-->(0, 0)-->(0, 1)-->(1, 1)-->(2, 1)-->(2, 0)-->(2, 1)-->(2, 0)-->(3, 0)-->(2, 0)-->(2, 0)-->(2, 0)-->(2, 1)-->(2, 2)-->(2, 1)-->(2, 2)-->(2, 1)-->(2, 2)-->(2, 1)-->(1, 1)-->(1, 2)-->(1, 3)-->(2, 3)  >>>fail<<<\n",
      "(0, 0)-->(1, 0)-->(2, 0)-->(3, 0)-->(3, 0)-->(2, 0)-->(2, 0)-->(3, 0)-->(4, 0)-->(3, 0)-->(3, 0)-->(4, 0)-->(4, 1)-->(4, 2)-->(4, 1)-->(3, 1)  >>>fail<<<\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "            \n",
    "######################################\n",
    "\n",
    "EPISODE = 30\n",
    "STEP_DELAY = 0.1\n",
    "EPISODE_DELAY = 2\n",
    "\n",
    "######################################\n",
    "# main function\n",
    "def process_Sarsa(agent):\n",
    "    for epi in range(EPISODE):\n",
    "        state = agent.new_episode() # init state\n",
    "        action = agent.choose_action(agent.state)\n",
    "\n",
    "        print(\"{}\".format(state),end='')\n",
    "        terminal = False\n",
    "        while not terminal:\n",
    "            next_state, reward, terminal = env.take_action(state, action)\n",
    "            next_action = agent.choose_action(next_state)\n",
    "            ### update sarsa table\n",
    "            agent.learn(reward, action, next_action, next_state)\n",
    "            ###\n",
    "            env.showEnvInfo(next_state, reward, terminal)\n",
    "            \n",
    "            state = agent.state = next_state\n",
    "            action = next_action\n",
    "            time.sleep(STEP_DELAY)\n",
    "            \n",
    "        time.sleep(EPISODE_DELAY)\n",
    "\n",
    "def process_QLearning(agent):\n",
    "    for epi in range(EPISODE):\n",
    "        state = agent.new_episode()\n",
    "        \n",
    "        print(\"{}\".format(agent.state),end='')\n",
    "        terminal = False\n",
    "        while not terminal:\n",
    "            state = agent.state\n",
    "            action = agent.choose_action(state)\n",
    "            next_state, reward, terminal = env.take_action(state, action)\n",
    "            ### update sarsa table\n",
    "            agent.learn(reward, action, next_state)\n",
    "            ###\n",
    "            env.showEnvInfo(next_state, reward, terminal)\n",
    "            agent.state = next_state\n",
    "            time.sleep(STEP_DELAY)\n",
    "            \n",
    "        time.sleep(EPISODE_DELAY)\n",
    "    \n",
    "################################################\n",
    "env = Env(fail_list=[(2,3),(3,1)])\n",
    "s_agent = SarsaAgent() # init agent and Q-table\n",
    "q_agent = QLearningAgent()\n",
    "    \n",
    "process_QLearning(q_agent)\n",
    "# process_Sarsa(s_agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.93505859,  0.        , -0.890625  ,  0.        ],\n",
       "        [-0.87841797,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.68603516,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.56982422,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.27099609,  0.        ,  0.        , -0.52197266]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.65136719,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.46875   ]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.61279297,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.18994141]],\n",
       "\n",
       "       [[ 0.        ,  0.        , -0.68603516,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.09997559]],\n",
       "\n",
       "       [[ 0.        , -0.27099609, -0.18994141,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]], dtype=float16)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_agent.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757747874034515"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# np.random.rand(1)[0]\n",
    "\n",
    "np.random.random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2,3)\n",
    "b= (2,)\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pooh'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocb_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
    "np.random.choice(vocb_arr, replace=False, p=[0.5, 0.1, 0.1, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])\n",
    "a[(1,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 3, 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (2,1)\n",
    "b= (3,0)\n",
    "a +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    }
   ],
   "source": [
    "class a:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def printA(self):\n",
    "        print('a')\n",
    "class b(a):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def printA(self):\n",
    "        print('b')\n",
    "        \n",
    "B = b()\n",
    "B.printA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5, 1, p=[0.1, 0, 0.3, 0.6, 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
