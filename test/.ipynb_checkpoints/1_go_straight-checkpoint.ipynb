{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# go straight game\n",
    "- its a 1-D (one dimension) problem with target T and ur status O on the line\n",
    "- Morvan tutorial ([link](https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/2-1-general-rl/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0],\n",
       " [0, 0]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# component for Q-table\n",
    "ACTIONS = ['left','right']\n",
    "nSTATE = 10 # status 0-9\n",
    "data = [[0]*len(ACTIONS)]*nSTATE # init. table data with 0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   left  right\n",
       "0     0      0\n",
       "1     0      0\n",
       "2     0      0\n",
       "3     0      0\n",
       "4     0      0\n",
       "5     0      0\n",
       "6     0      0\n",
       "7     0      0\n",
       "8     0      0\n",
       "9     0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table = pd.DataFrame(data=data, columns=ACTIONS)\n",
    "Q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPSILON = 0.8  # 80% choose highest reward action and 20% choose randomly\n",
    "\n",
    "def choose_action(state):\n",
    "    state_actions = Q_table.iloc[state]\n",
    "    # 隨機值大於0.8(epsilon value) 或 第一次進入該state --> 隨機選取action\n",
    "    if (np.random.uniform() > EPSILON) or (state_actions.all()==0):\n",
    "        return np.random.choice(ACTIONS) # 隨機選取action\n",
    "    else:\n",
    "        return state_actions.argmax() #derive highest reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting feedback from env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With state and action you take, you can get env. feedback\n",
    "def env_feedback(state, action):\n",
    "    if action == 'right':\n",
    "        if state == nSTATE-2: #before terminate\n",
    "            next_state = 'terminate'\n",
    "            reward = 1\n",
    "        else:\n",
    "            next_state = state +1\n",
    "            reward = 0\n",
    "    else: # move left\n",
    "        reward = 0 #this action wont reach target, so reward always = 0 in the action\n",
    "        if state == 0:\n",
    "            next_state = state # reah the wall :3\n",
    "        else:\n",
    "            next_state = state - 1\n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# env and agent state visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STEP_TIME = 0.1\n",
    "\n",
    "def update_visual_env(state, episode, step_count):\n",
    "    env_list = ['-']*(nSTATE-1)+['T']  # '---------T' is our environment\n",
    "    if state == 'terminate':\n",
    "        interaction = 'Episode %s: total_steps = %s' % (episode+1, step_count) # string\n",
    "        print('\\r{}'.format(interaction), end='\\n') # wont change line if end='\\n'\n",
    "        time.sleep(2) # sleep 2 sec\n",
    "        print('\\r                      ', end='') # refresh line\n",
    "    else : \n",
    "        env_list[state] = 'o'\n",
    "        interaction = ''.join(env_list)\n",
    "        print('\\r{}'.format(interaction), end='')\n",
    "        time.sleep(STEP_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Q-Learning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_EPISODES = 13\n",
    "GAMMA = 0.9 # decay rate\n",
    "ALPHA = 0.1 # learning rate\n",
    "\n",
    "# No need to think but follow Q-Learning algorithm\n",
    "def Q_Learning():\n",
    "    for episode in range(MAX_EPISODES):\n",
    "        step_count = 0\n",
    "        state = 0\n",
    "        is_terminated = False\n",
    "        update_visual_env(state, episode, step_count) # update env and show\n",
    "        while not is_terminated:\n",
    "            action = choose_action(state)\n",
    "            next_state, reward = env_feedback(state, action) #in this case: {terminal:1,otherwise:0}\n",
    "            #print('state : '+ str(state))\n",
    "            q_predict = Q_table.ix[state, action] #get Q_table value\n",
    "            if next_state == 'terminate':\n",
    "                q_target = reward        # reward=1 ,\n",
    "                is_terminated = True   # also means episode finish\n",
    "            else:\n",
    "                # pick max reward at next state's actions,\n",
    "                # multiply by decay rate GAMMA, \n",
    "                # and Add reward and previous result together \n",
    "                q_target = reward + GAMMA * Q_table.iloc[next_state, :].max()\n",
    "            \n",
    "            # update Q-table with q_target and predict one,\n",
    "            # which q_target was measured by next state\n",
    "            Q_table.ix[state, action] += ALPHA * (q_target - q_predict)\n",
    "            state = next_state # finally update state\n",
    "            \n",
    "            #Optional :P (just for visualization)\n",
    "            update_visual_env(state, episode, step_count+1) # update env. after state update\n",
    "            step_count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "o--------T\r",
      "o--------T"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bl515/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: total_steps = 58\n",
      "Episode 2: total_steps = 37\n",
      "Episode 3: total_steps = 141\n",
      "Episode 4: total_steps = 15\n",
      "Episode 5: total_steps = 32\n",
      "Episode 6: total_steps = 10\n",
      "Episode 7: total_steps = 12\n",
      "Episode 8: total_steps = 9\n",
      "Episode 9: total_steps = 11\n",
      "Episode 10: total_steps = 11\n",
      "Episode 11: total_steps = 9\n",
      "Episode 12: total_steps = 12\n",
      "Episode 13: total_steps = 11\n",
      "                      "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.416758e-08</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.141639e-08</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.178877e-10</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.856714e-06</td>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.653447e-05</td>\n",
       "      <td>0.006352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.904900e-07</td>\n",
       "      <td>0.033230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.139991e-05</td>\n",
       "      <td>0.128973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.290000e-05</td>\n",
       "      <td>0.364226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.841273e-02</td>\n",
       "      <td>0.745813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           left     right\n",
       "0  2.416758e-08  0.000001\n",
       "1  1.141639e-08  0.000014\n",
       "2  8.178877e-10  0.000135\n",
       "3  5.856714e-06  0.001244\n",
       "4  8.653447e-05  0.006352\n",
       "5  5.904900e-07  0.033230\n",
       "6  4.139991e-05  0.128973\n",
       "7  7.290000e-05  0.364226\n",
       "8  1.841273e-02  0.745813\n",
       "9  0.000000e+00  0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_Learning()\n",
    "Q_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
